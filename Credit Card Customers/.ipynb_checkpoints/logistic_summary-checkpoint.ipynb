{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic regression \n",
    "- 로지스틱 회귀란 선형회귀방식을 분류에 적용한 알고리즘임 \n",
    "- 학습을 통해 선형 함수의 회귀 최적선을 찾는 것이 아니라, 시그모이드 함수 최적선을 찾고 이 시그모이드 함수의 반환 값을 확률로 간주해 확률에 따라 분류를 결정 \n",
    "- 시그모이드 함수는 아래 식과 같이 구성되어 있고, y값은 0~1사이 값을 반환 함   \n",
    "\n",
    "$$\n",
    "수식넣기 \n",
    "$$ \n",
    "\n",
    "## 2. 선형회귀분석 >> 로지스틱 회귀분석  \n",
    "![logitstic_regression](https://user-images.githubusercontent.com/49746140/106357602-62b9b700-634a-11eb-88f3-531ca811aee8.JPG)\n",
    " \n",
    "- 좌측 그림과 같이, 선형 회귀분석을 사용해서 fitting을 하게 된다면 위 문제의 목적은 A와 B, 두 카테고리를 분류하고자 하는 문제이기 때문에 y값을 정확히 예측하기에는 어려움 (-lnf ~ lnf)\n",
    "- y값을 예측하기 위해서는 우측 그림처럼 0~1의 값을 가지도록 수식을 변환시켜줘야함 \n",
    "\n",
    "- 0 ~ 1로 바꾸기 위해 \n",
    "### 1) P대신 Odds로 변환 (0 ~ lnf) \n",
    "- Odds = p/1-p = ax + b \n",
    "### 2) Odds에 Log를 씌우기 \n",
    "- log(Odds) = log(p/1-p) = ax + b \n",
    "### 3) 위 식을 풀어쓰면  \n",
    "\n",
    "\n",
    "\n",
    "- 의 범위를 가지고 있기 때문에\n",
    "좌측 그림과 같이, Y의 값을 예측하기위해 선형회귀를 fitting 하는 것은 어렵다. 따라서 곡선으로 fitting 하기 위해 사용하게 되는 것이 logistic 함수 = 로짓변환이다. \n",
    "- 로짓은 실패에 비해 성공할 확률을 의미하는 \"odds = p / 1-p\"에 Log변환을 취한 값 log(p / 1-p) \n",
    "- 독립변수 x에 대한 선형회귀식을 x가 주어졌을 때의 반응 변수 y의 로그 오즈에 적합시킨다고 할 수 있음 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
